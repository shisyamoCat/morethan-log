{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1R0K5gQuog1y2S63MyGNkHeizXw06daQy",
      "authorship_tag": "ABX9TyMq/vzb8xLBXJ4GepcYXV0F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shisyamoCat/morethan-log/blob/main/matching_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# シートを出力するか true = 0, false = 1\n",
        "# 'rms管材王マッチングデータ（重複分）'シートの出力フラグ\n",
        "is_duplicate = 0\n",
        "# '商品番号'シートの出力フラグ\n",
        "is_extract_number = 0\n",
        "# '選択肢タイプ'シートの出力フラグ\n",
        "is_option_type = 0\n",
        "# '除外'シートの出力フラグ\n",
        "is_exceptions = 0"
      ],
      "metadata": {
        "id": "ZdFNcoGB-Qkf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FMqnHCrCq5-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afea333f-e622-42a3-b035-60b274828186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# '/content/drive/MyDrive'がgoogleドライブを開いた際に表示されるマイドライブ\n",
        "# ドライブをマウントするために初回１度だけ実行\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time"
      ],
      "metadata": {
        "id": "_nvYRLQEx07Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モジュールを保存するディレクトリのパス\n",
        "module_dir = '/content/drive/MyDrive/matchingData/modules'\n",
        "\n",
        "# ディレクトリが存在しない場合は作成\n",
        "if not os.path.exists(module_dir):\n",
        "    os.makedirs(module_dir)\n",
        "\n",
        "# モジュールインストール先を指定してインストール\n",
        "# 初回インストール後はコメントアウトorリムーブ\n",
        "# !pip install --target=$module_dir xlsxwriter\n",
        "\n",
        "# モジュールのパスをシステムパスに追加\n",
        "sys.path.append(module_dir)"
      ],
      "metadata": {
        "id": "1IeGsF9CQKiY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------------------\n",
        "# 関数定義\n",
        "#------------------------------------------------------------------------\n",
        "\n",
        "# 除外を抽出する関数\n",
        "def extract_exceptions(df):\n",
        "    # 抜き出す条件の文字列（後ろに追加するだけで自動的にソート）\n",
        "    target_strings = sorted(['15zd-eliturbo2002', '10221600'])\n",
        "\n",
        "    # 連結後のデータの対象列（例えば、'商品管理番号（商品URL）'を想定）\n",
        "    column_to_search = '商品管理番号（商品URL）'\n",
        "\n",
        "    # 二分探索で部分一致を確認する関数\n",
        "    def binary_search_contains_partial(search_value, target_list):\n",
        "        for target in target_list:\n",
        "            if target in search_value:  # 部分一致を確認\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    # 連結後のデータから除外対象の行を抽出\n",
        "    df_exceptions = df[df.apply(lambda row: binary_search_contains_partial(str(row[column_to_search]), target_strings), axis=1)]\n",
        "\n",
        "    return df_exceptions\n",
        "\n",
        "# 選択肢タイプを抽出する関数\n",
        "def extract_option_type(df):\n",
        "    # `商品管理番号（商品URL）` がエンプティではなく、`選択肢タイプ` がエンプティでない行を抽出\n",
        "    df_option_type = df[\n",
        "        df['商品管理番号（商品URL）'].notna() & df['選択肢タイプ'].notna()\n",
        "    ]\n",
        "\n",
        "    return df_option_type\n",
        "\n",
        "# 商品番号を抽出する関数\n",
        "def extract_item_number(df):\n",
        "    # 商品番号列にデータが入っている行を抽出し、`商品管理番号（商品URL）` 列でソート\n",
        "    df_with_item_number = df[df['商品番号'].notna()]\n",
        "    df_with_item_number = df_with_item_number.sort_values(by='商品管理番号（商品URL）', ascending=True)\n",
        "\n",
        "    return df_with_item_number\n",
        "\n",
        "# マッチングデータを補完する関数\n",
        "def data_matching(df, item_number):\n",
        "    # 商品管理番号の列名を変数化\n",
        "    product_url_column = '商品管理番号（商品URL）'\n",
        "\n",
        "    # 抽出した行を元のデータから削除し、残りのデータをソート\n",
        "    df = df[~df.index.isin(item_number.index)]\n",
        "    df = df.sort_values(by=product_url_column, ascending=True)\n",
        "\n",
        "    # 補完列名\n",
        "    complements_columns = ['商品番号', 'バリエーション6選択肢定義']\n",
        "\n",
        "    # complements_columns の範囲に基づいて列を取得\n",
        "    try:\n",
        "        update_columns = df.columns[df.columns.get_loc(complements_columns[0]):\n",
        "                                    df.columns.get_loc(complements_columns[1]) + 1]\n",
        "    except KeyError as e:\n",
        "        print(f\"列名が見つかりません: {e}\")\n",
        "        raise\n",
        "\n",
        "    # dfの商品管理番号（商品URL）に基づいてitem_numberをソート・拡張\n",
        "    df_product_urls = df[product_url_column].values\n",
        "    item_number_sorted = item_number.set_index(product_url_column).loc[df_product_urls].reset_index()\n",
        "\n",
        "    # 更新マスクを作成\n",
        "    update_mask = item_number_sorted[update_columns[0]].notna().values\n",
        "\n",
        "    # ベクトル化された更新\n",
        "    for col in update_columns:\n",
        "        df.loc[update_mask, col] = item_number_sorted.loc[update_mask, col].values\n",
        "\n",
        "    return df\n",
        "\n",
        "# 重複分を抽出する関数\n",
        "def extract_duplicate(df):\n",
        "    # '商品管理番号（商品URL）' 列で重複する行をピックアップ\n",
        "    df_duplicate_rows = df[df.duplicated(subset='商品管理番号（商品URL）', keep=False)]\n",
        "\n",
        "    return df_duplicate_rows\n",
        "\n",
        "def convert_to_numeric_if_possible(value):\n",
        "    try:\n",
        "        # 数値に変換可能な場合は変換\n",
        "        return pd.to_numeric(value, errors='raise')\n",
        "    except (ValueError, TypeError):\n",
        "        # 数値に変換できない場合はそのまま返す\n",
        "        return value\n",
        "\n",
        "def convert_column_to_numeric_if_possible(df, column_name):\n",
        "    # 指定された列を数値に変換可能であれば変換\n",
        "    df[column_name] = df[column_name].apply(convert_to_numeric_if_possible)\n",
        "\n",
        "    return df\n",
        "\n",
        "# 数値と文字列の行を分離\n",
        "def separate_num_and_str(df, column_name):\n",
        "    # 数値化可能なら数値化\n",
        "    df[column_name] = df[column_name].apply(convert_to_numeric_if_possible)\n",
        "\n",
        "    # 数値と文字列でデータフレームを分ける\n",
        "    numeric_rows = df[pd.to_numeric(df[column_name], errors='coerce').notna()]  # 数値行\n",
        "\n",
        "    string_rows = df[pd.to_numeric(df[column_name], errors='coerce').isna()]    # 文字列行\n",
        "\n",
        "    # 数値⇒文字列の順に結合\n",
        "    df_separate = pd.concat([numeric_rows, string_rows])\n",
        "\n",
        "    return df_separate\n",
        "\n",
        "# 文字を変換\n",
        "def convert_to_string(df, before, after):\n",
        "    # applymapを使って全てのセルに対して処理を適用\n",
        "    df = df.applymap(lambda x: x.replace(before, after) if isinstance(x, str) else x)\n",
        "    return df\n",
        "\n",
        "# DataFrameをExcelシートに書き込む関数\n",
        "def write_to_excel(writer, df, sheet_name):\n",
        "    if not df.empty:  # データフレームが空でないかチェック\n",
        "        # NaNを空白に変換し、型を推定\n",
        "        df = df.fillna('').infer_objects(copy=False)\n",
        "\n",
        "        # xlsx形式のファイル内の各シートに書き出し\n",
        "        df.to_excel(writer, index=False, sheet_name=sheet_name)\n",
        "\n",
        "def display_elapsed_time(start_time):\n",
        "    elapsed_time = time.time() - start_time\n",
        "    hours = int(elapsed_time // 3600)\n",
        "    minutes = int((elapsed_time % 3600) // 60)\n",
        "    seconds = elapsed_time % 60\n",
        "\n",
        "    print(f\"\\n処理にかかった時間: {hours}時間 {minutes}分 {seconds:.2f}秒\")"
      ],
      "metadata": {
        "id": "5paVMij_3Ty0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 処理開始時刻を取得\n",
        "start_time_total = time.time()"
      ],
      "metadata": {
        "id": "PNo-ndzywNcE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------------------\n",
        "# ファイルを全て読み込み、商品属性40~100をオミット\n",
        "# データを加工して各シートに書き込むデータフレームを作成\n",
        "#------------------------------------------------------------------------\n",
        "\n",
        "# 処理開始時刻を取得\n",
        "start_time = time.time()\n",
        "\n",
        "# CSVファイルが保存されているディレクトリのパス\n",
        "rms_dir_path = '/content/drive/MyDrive/matchingData/data/rms/'\n",
        "\n",
        "# ディレクトリ内の全CSVファイルを取得\n",
        "csv_files = [f for f in os.listdir(rms_dir_path) if f.endswith('.csv')]\n",
        "\n",
        "# 削除したい列のリスト\n",
        "pattern = re.compile(r'商品属性（(項目|値|単位)）([4-9][0-9]|100)$')\n",
        "\n",
        "# 読み込んだデータを保存するデータフレーム\n",
        "exceptions_df = pd.DataFrame()\n",
        "option_type_df = pd.DataFrame()\n",
        "extract_number_df = pd.DataFrame()\n",
        "data_matching_df = pd.DataFrame()\n",
        "duplicate_rows_df = pd.DataFrame()\n",
        "filterd_df = pd.DataFrame()\n",
        "\n",
        "# エンコーディングを指定\n",
        "encoding_used = 'shift_jis'\n",
        "\n",
        "# すべてのCSVファイルを格納するためのリスト\n",
        "df_list = []\n",
        "\n",
        "# ファイル読み込み\n",
        "for i, file in enumerate(csv_files):\n",
        "    # ファイルのパスを取得\n",
        "    file_path = os.path.join(rms_dir_path, file)\n",
        "\n",
        "    try:\n",
        "        # RMSデータをデータフレームに読み込み\n",
        "        df = pd.read_csv(file_path, encoding=encoding_used, low_memory=False, dtype=str)\n",
        "\n",
        "        # データフレームをリストに追加\n",
        "        df_list.append(df)\n",
        "\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"エンコードエラーが発生しました: {file_path}\")\n",
        "        print(e)\n",
        "\n",
        "# すべてのデータフレームを連結\n",
        "df_combined = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# 削除対象の列を特定（正規表現にマッチする列）\n",
        "columns_to_remove = [col for col in df_combined.columns if pattern.match(col)]\n",
        "\n",
        "# 削除対象の列があれば削除\n",
        "df_combined = df_combined.drop(columns=columns_to_remove, errors='ignore')\n",
        "\n",
        "# [除外]を抽出\n",
        "exceptions = extract_exceptions(df_combined)\n",
        "# [除外]データフレームにデータを追加\n",
        "exceptions_df = pd.concat([exceptions_df, exceptions], ignore_index=True)\n",
        "# [マッチングデータ]から[除外]データを削除\n",
        "df_filtered = df_combined[~df_combined.index.isin(exceptions.index)]\n",
        "\n",
        "# [選択肢タイプ]を抽出\n",
        "option_type = extract_option_type(df_filtered)\n",
        "# [選択肢タイプ]データフレームにデータを追加\n",
        "option_type_df = pd.concat([option_type_df, option_type], ignore_index=True)\n",
        "# [マッチングデータ]から[選択肢タイプ]データを削除\n",
        "df_filtered = df_filtered.drop(option_type.index)\n",
        "\n",
        "# [商品番号]を抽出\n",
        "extract_number = extract_item_number(df_filtered)\n",
        "# [商品番号]データフレームにデータを追加\n",
        "extract_number_df = pd.concat([extract_number_df, extract_number], ignore_index=True)\n",
        "# [マッチングデータ]から[商品番号]データを削除\n",
        "df_filtered = df_filtered.drop(extract_number.index)\n",
        "\n",
        "# [rms管材王マッチングデータ]を補完\n",
        "complement_data_matching = data_matching(df_filtered, extract_number)\n",
        "# データフレームにデータを追加\n",
        "data_matching_df = pd.concat([data_matching_df, complement_data_matching], ignore_index=True)\n",
        "\n",
        "# [rms管材王マッチングデータ（重複分）]を抽出\n",
        "duplicate_rows = extract_duplicate(complement_data_matching)\n",
        "# [rms管材王マッチングデータ（重複分）]データフレームにデータを追加\n",
        "duplicate_rows_df = pd.concat([duplicate_rows_df, duplicate_rows], ignore_index=True)\n",
        "# [マッチングデータ]から[rms管材王マッチングデータ（重複分）]データを削除\n",
        "df_filtered = complement_data_matching.drop(duplicate_rows.index)\n",
        "\n",
        "# 重複行を [マッチングデータ]データフレーム から削除\n",
        "df_filtered = df_filtered[~df_filtered.index.isin(duplicate_rows.index)]\n",
        "\n",
        "# [マッチングデータ]データフレームにマッチングデータを追加\n",
        "filterd_df = pd.concat([filterd_df, df_filtered], ignore_index=True)\n",
        "\n",
        "# '商品管理番号（商品URL）'列の値でソート\n",
        "filterd_df = filterd_df.sort_values(by='商品管理番号（商品URL）', ascending=True)\n",
        "\n",
        "# 経過時間を出力（秒単位）\n",
        "display_elapsed_time(start_time)"
      ],
      "metadata": {
        "id": "yQu-q3xO6SMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17029f18-1338-49cb-af1e-d95d39dd3160"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "処理にかかった時間: 0時間 1分 41.42秒\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------------------\n",
        "# 管材王のデータをdf_kanzaiに読み込み\n",
        "#------------------------------------------------------------------------\n",
        "\n",
        "# 処理開始時刻を取得\n",
        "start_time = time.time()\n",
        "\n",
        "import glob\n",
        "\n",
        "# ディレクトリのパス\n",
        "directory_path = '/content/drive/MyDrive/matchingData/data/kanzai/'\n",
        "\n",
        "# .xlsxファイルのパスを取得\n",
        "xlsx_files = glob.glob(directory_path + '*.xlsx')\n",
        "\n",
        "# 空のリストにデータフレームを格納する\n",
        "df_list = []\n",
        "\n",
        "# 複数ファイルをループ処理\n",
        "for i, file in enumerate(xlsx_files):\n",
        "    # 最初のファイルはヘッダーを含めて読み込み\n",
        "    df = pd.read_excel(file, dtype=str)\n",
        "\n",
        "    # データフレームをリストに追加\n",
        "    df_list.append(df)\n",
        "\n",
        "# すべてのデータフレームを連結\n",
        "df_kanzai = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# 変換する列のリスト\n",
        "columns_to_convert = [\n",
        "    'M30_TANK11', 'M30_TANK12', 'M30_TANK13', 'M30_TANK14',\n",
        "    'M30_TANK15', 'M30_TANK16', 'M30_TANK2', 'M30_HACU1',\n",
        "    'M30_KUBN1', 'M30_KUBN2', 'M30_KUBN3', 'M30_KUBN4',\n",
        "    'M30_KUBN5', 'M30_SURY1', 'M30_SURY2', 'M30_SURY3',\n",
        "    'M30_BIRI1', 'M30_BIRI2'\n",
        "]\n",
        "\n",
        "# 特定の列をfloat型に変換し、.0のみ丸める\n",
        "for col in columns_to_convert:\n",
        "    if col in df_kanzai.columns:\n",
        "        # float型に変換\n",
        "        df_kanzai[col] = df_kanzai[col].astype(float)\n",
        "\n",
        "# .0の値を整数に変換し、.1～.9はそのままにする\n",
        "df_kanzai.replace({.0: 0}, inplace=True)\n",
        "\n",
        "# 経過時間を出力（秒単位）\n",
        "display_elapsed_time(start_time)"
      ],
      "metadata": {
        "id": "QWyPinB9jLMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e75f444-c5d8-40f6-a51f-38be1d08bfed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "処理にかかった時間: 0時間 3分 5.42秒\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------------------\n",
        "# 管材王のデータヘッダーをfilterd_dfに設定\n",
        "#------------------------------------------------------------------------\n",
        "\n",
        "# 処理開始時刻を取得\n",
        "start_time = time.time()\n",
        "\n",
        "# 現在のcolumnsの長さを確認\n",
        "current_columns_length = len(filterd_df.columns)\n",
        "\n",
        "# 必要な列数\n",
        "required_columns = 453\n",
        "\n",
        "new_headers = list(df_kanzai.columns)\n",
        "\n",
        "if current_columns_length > required_columns:\n",
        "    # 列数が多すぎる場合、余分な列を削除\n",
        "    filterd_df = filterd_df.iloc[:, :required_columns]\n",
        "elif current_columns_length < required_columns:\n",
        "    # 列数が足りない場合、空の列を一度に追加する\n",
        "    columns_to_add = required_columns - current_columns_length\n",
        "    empty_columns = pd.DataFrame(pd.NA, index=filterd_df.index, columns=[f'Empty_{i+1}' for i in range(columns_to_add)])\n",
        "    filterd_df = pd.concat([filterd_df, empty_columns], axis=1)\n",
        "\n",
        "# 新しいヘッダーリストを作成\n",
        "new_column_list = list(filterd_df.columns[:375]) + [''] * (required_columns - 375 - len(new_headers)) + new_headers\n",
        "\n",
        "# 新しいヘッダーを設定\n",
        "filterd_df.columns = new_column_list\n",
        "\n",
        "print(\"ヘッダーが設定されました。\")\n",
        "\n",
        "# 経過時間を出力（秒単位）\n",
        "display_elapsed_time(start_time)"
      ],
      "metadata": {
        "id": "mmdg3O2893mK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fb696e0-2752-446b-ed1a-b04a9e34fafd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ヘッダーが設定されました。\n",
            "\n",
            "処理にかかった時間: 0時間 0分 1.55秒\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------------------\n",
        "# 管材王のデータをRMSデータにコンバイン\n",
        "#------------------------------------------------------------------------\n",
        "\n",
        "# 処理開始時刻を取得\n",
        "start_time = time.time()\n",
        "\n",
        "# 文字列化する列名を指定\n",
        "column_name = '商品管理番号（商品URL）'\n",
        "\n",
        "# df_kanzaiのM30_CODE3列をすべて文字列に変換し、NaN値を処理\n",
        "df_kanzai['M30_CODE3'] = df_kanzai['M30_CODE3'].fillna('').astype(str)\n",
        "\n",
        "# df_kanzaiを'M30_CODE3'列でソートし、インデックスをリセット\n",
        "df_kanzai_sorted = df_kanzai.sort_values('M30_CODE3').reset_index(drop=True)\n",
        "\n",
        "# 二分探索のための関数を定義\n",
        "def binary_search(arr, x):\n",
        "    low = 0\n",
        "    high = len(arr) - 1\n",
        "    mid = 0\n",
        "\n",
        "    while low <= high:\n",
        "        mid = (high + low) // 2\n",
        "        if arr[mid] < x:\n",
        "            low = mid + 1\n",
        "        elif arr[mid] > x:\n",
        "            high = mid - 1\n",
        "        else:\n",
        "            return mid\n",
        "    return -1  # 要素が見つからない場合\n",
        "\n",
        "# M30_CODE3列の値を配列として取得\n",
        "m30_codes = df_kanzai_sorted['M30_CODE3'].values\n",
        "\n",
        "# filterd_dfの'商品管理番号（商品URL）'列の値を文字列に書き換え\n",
        "filterd_df[column_name] = filterd_df[column_name].astype(str)\n",
        "\n",
        "# '商品管理番号（商品URL）'列をベースにソート\n",
        "filterd_df.sort_values(by=column_name, ascending=True)\n",
        "\n",
        "# NumPy配列に変換\n",
        "kanzai_values = df_kanzai_sorted.values\n",
        "\n",
        "# デフォルトを '#N/A' で埋めるために、dtype=object を指定\n",
        "na_filled_array = np.full((filterd_df.shape[0], df_kanzai_sorted.shape[1]), '#N/A', dtype=object)\n",
        "\n",
        "for idx, value in enumerate(filterd_df[column_name]):\n",
        "    matched_index = binary_search(m30_codes, value)\n",
        "    if matched_index != -1:\n",
        "        na_filled_array[idx] = kanzai_values[matched_index]\n",
        "\n",
        "# 一括でfilterd_dfの416列目以降を更新\n",
        "filterd_df.iloc[:, 416:416 + df_kanzai_sorted.shape[1]] = na_filled_array\n",
        "\n",
        "# データフレーム内の数値をint型に変換\n",
        "filterd_df.iloc[:, :375] = filterd_df.iloc[:, :375].apply(convert_to_numeric_if_possible)\n",
        "\n",
        "# 変更を確認\n",
        "print(\"データがコピーされました。\")\n",
        "\n",
        "# 経過時間を出力（秒単位）\n",
        "display_elapsed_time(start_time)"
      ],
      "metadata": {
        "id": "ixo1eFmaxEY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfa57206-c66a-4b6d-ca54-e1e51973fb00"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "データがコピーされました。\n",
            "\n",
            "処理にかかった時間: 0時間 0分 15.16秒\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------------------\n",
        "# RMSデータ変換、文字列⇒数値したのちソート\n",
        "#------------------------------------------------------------------------\n",
        "\n",
        "# 処理開始時刻を取得\n",
        "start_time = time.time()\n",
        "\n",
        "# 〜 (Unicode: 12316) を ～ (Unicode: 65374) に統一\n",
        "filterd_df = convert_to_string(filterd_df, '〜', '～')\n",
        "\n",
        "# '£' を '￡' に変換\n",
        "filterd_df = convert_to_string(filterd_df, '£', '￡')\n",
        "\n",
        "# 'ポイント変倍率適用期間（開始日時）' と 'ポイント変倍率適用期間（終了日時）' の両方の列に対して\n",
        "# '/' を '-' に変換\n",
        "target_point_columns = ['ポイント変倍率適用期間（開始日時）', 'ポイント変倍率適用期間（終了日時）']\n",
        "filterd_df[target_point_columns] = filterd_df[target_point_columns].apply(lambda x: x.str.replace('/', '-'))\n",
        "\n",
        "# 数値⇒文字列の順にソート\n",
        "filterd_df = separate_num_and_str(filterd_df, '商品管理番号（商品URL）')\n",
        "\n",
        "# 当該列名リスト\n",
        "target_description_columns = ['PC用商品説明文', 'スマートフォン用商品説明文']\n",
        "\n",
        "# 375列目までに制限し、除外列以外を数値化可能なら変換\n",
        "filterd_df.loc[:, filterd_df.columns[:375][~filterd_df.columns[:375].isin(target_description_columns)]] = \\\n",
        "    filterd_df.loc[:, filterd_df.columns[:375][~filterd_df.columns[:375].isin(target_description_columns)]].applymap(convert_to_numeric_if_possible)\n",
        "\n",
        "def process_cell(x):\n",
        "    # 文字列に変換\n",
        "    x = str(x)\n",
        "    # 半角「=」または全角「＝」で囲まれた部分を抽出\n",
        "    match = re.search(r'[=＝](.+?)[=＝]', x)\n",
        "    if match:\n",
        "        content = match.group()\n",
        "        # 半角の「=」を全角の「＝」に変換\n",
        "        content = content.replace('=', '＝')\n",
        "        # 「＝」で始まる場合、先頭にゼロ幅非接合子を追加\n",
        "        if content.startswith('＝'):\n",
        "            return f'\\u200C{content}'\n",
        "        else:\n",
        "            return content\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "for col in target_description_columns:\n",
        "    filterd_df[col] = filterd_df[col].apply(process_cell)\n",
        "\n",
        "# 経過時間を出力（秒単位）\n",
        "display_elapsed_time(start_time)"
      ],
      "metadata": {
        "id": "zOa1Q34xmDSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e68d1962-c931-4c04-9cbc-60b1b475c4b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-3b0e96b86e4f>:114: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: x.replace(before, after) if isinstance(x, str) else x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------------------\n",
        "# 各シートへ対象データを書き出し、ファイル作成\n",
        "#------------------------------------------------------------------------\n",
        "\n",
        "# 処理開始時刻を取得\n",
        "start_time = time.time()\n",
        "\n",
        "# 出力ファイルパス（xlsx形式）\n",
        "output_file = '/content/drive/MyDrive/matchingData/data/matching_data.xlsx'\n",
        "\n",
        "# ExcelWriterを使用して複数のシートに書き込む\n",
        "with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
        "    # メインのデータを [rms管材王マッチングデータ] シートに保存\n",
        "    write_to_excel(writer, filterd_df, 'rms管材王マッチングデータ')\n",
        "\n",
        "    # df_filteredを [rms管材王マッチングデータ（重複分）] シートに保存\n",
        "    if is_duplicate == 1:\n",
        "        write_to_excel(writer, duplicate_rows_df, 'rms管材王マッチングデータ（重複分）')\n",
        "\n",
        "    # `商品番号` がエンプティではない行を [商品番号] シートに保存\n",
        "    if is_extract_number == 1:\n",
        "        write_to_excel(writer, extract_number_df, '商品番号')\n",
        "\n",
        "    # `商品管理番号（商品URL）` がエンプティではなく、`選択肢タイプ` がエンプティでない行を [選択肢タイプ] シートに保存\n",
        "    if is_option_type == 1:\n",
        "        write_to_excel(writer, option_type_df, '選択肢タイプ')\n",
        "\n",
        "    # 抜き出した行を [例外] シートに保存\n",
        "    if is_exceptions == 1:\n",
        "        write_to_excel(writer, exceptions_df, '例外')\n",
        "\n",
        "    # フォーマットを適用するためのワークブックとシートを取得\n",
        "    workbook = writer.book\n",
        "    sheets = writer.sheets\n",
        "\n",
        "    # MSゴシックフォントのフォーマットを定義\n",
        "    ms_gothic_format = workbook.add_format({'font_name': 'MS Gothic', 'font_size': 11})\n",
        "\n",
        "    # 中央寄せのフォーマットを定義\n",
        "    center_format = workbook.add_format({'align': 'center', 'valign': 'vcenter'})\n",
        "\n",
        "    # [rms管材王マッチングデータ]シートに対してフォーマットを適用\n",
        "    worksheet = sheets['rms管材王マッチングデータ']\n",
        "\n",
        "    # データ範囲を取得（行数、列数）\n",
        "    rows, cols = df.shape\n",
        "\n",
        "    # #N/Aセルに対して中央寄せの条件付きフォーマットを適用\n",
        "    worksheet.conditional_format(1, 0, rows, cols - 1,\n",
        "                             {'type': 'text',\n",
        "                              'criteria': 'containing',\n",
        "                              'value': '#N/A',\n",
        "                              'format': center_format})\n",
        "\n",
        "    # フォーマットをデータ範囲に適用\n",
        "    worksheet.set_column(0, cols - 1, None, ms_gothic_format)\n",
        "\n",
        "print(f\"\\nデータを {output_file} に保存しました。\")\n",
        "\n",
        "# 経過時間を出力（秒単位）\n",
        "display_elapsed_time(start_time)"
      ],
      "metadata": {
        "id": "-N3X6-_gxfH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 経過時間を出力（秒単位）\n",
        "display_elapsed_time(start_time_total)"
      ],
      "metadata": {
        "id": "Z1ODpSFQwTkc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}